/-
  Given two real numbers \(a\) and \(b\) such that \(a^2 + b^2 = 1\), we need to show that \(ab + (a - b) \leq 1\).
  1. Consider the expression \(a^2 + b^2\). Since \(a^2 + b^2 = 1\), we can use this fact to bound the terms in the inequality.
  2. We start by rewriting the inequality \(ab + (a - b) \leq 1\) in a form that allows us to use the given condition.
  3. We use the non-negativity of squares to derive the desired inequality. Specifically, we consider the squares of \(a + b\), \(a - b\), and \(a \cdot b - 1\).
  4. By applying the non-negativity of these squares, we can establish the required inequality.
  -/
  -- We use the non-negativity of squares to derive the inequality.
  -- Specifically, we consider the squares of (a + b), (a - b), and (a * b - 1).
  nlinarith [sq_nonneg (a + b), sq_nonneg (a - b), sq_nonneg (a * b - 1)]
  -- By applying the non-negativity of these squares, we can establish the required inequality.
  <;>
  -- Use linear arithmetic to conclude the proof.
  linarith [hâ‚€]
```