/-
  Given two real numbers \(a\) and \(b\) such that \(a^2 + b^2 = 1\), we need to show that \(ab + (a - b) \leq 1\). We start by considering the non-negativity of certain squares involving \(a\) and \(b\). Specifically, we use the fact that the square of any real number is non-negative. We then use these inequalities to derive the desired result.
  1. We note that \((a - b)^2 \geq 0\) because the square of any real number is non-negative.
  2. Similarly, \((a + b)^2 \geq 0\) for the same reason.
  3. We also consider \((a + b - 2)^2 \geq 0\) and \((a + b + 2)^2 \geq 0\).
  4. Using these inequalities, we can derive the desired result by applying non-linear arithmetic reasoning.
  -/
  -- We use the non-negativity of squares to derive useful inequalities.
  have h₁ := sq_nonneg (a - b) -- h₁: (a - b)^2 ≥ 0
  have h₂ := sq_nonneg (a + b) -- h₂: (a + b)^2 ≥ 0
  have h₃ := sq_nonneg (a + b - 2) -- h₃: (a + b - 2)^2 ≥ 0
  have h₄ := sq_nonneg (a + b + 2) -- h₄: (a + b + 2)^2 ≥ 0
  -- Using the non-negativity of these squares and the given condition a^2 + b^2 = 1,
  -- we apply non-linear arithmetic to prove the desired inequality.
  nlinarith [h₀, h₁, h₂, h₃, h₄]
```